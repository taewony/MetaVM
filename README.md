# MetaVM 프로젝트

---
> *"AI 시대를 위한 새로운 '컴퓨팅 언어 실험실'"*
---

## 🚀 프로젝트 개요 및 목표

MetaVM 프로젝트는 **AI 통합 협업 프로그래밍 모델 및 개발 프로세스**에 대한 연구와 개발을 목표로 합니다. 이 프로젝트는 다음과 같은 구성 요소를 갖춘 실험적인 프레임워크를 제공합니다:

* **MetaVM/IR (Meta Virtual Machine / Intermediate Representation):** 새로운 개발 워크플로우를 가능하게 하는 핵심 인프라입니다.
* **MiniLang:** 명확한 데이터 흐름 의미론을 통해 데이터 분석 및 자동화 작업을 표현하는 데 중점을 둔 맞춤형 **DSL(도메인 특화 언어)**입니다.
* **AI 통합:** 코드 생성(자연어 -> MiniLang/IR)을 위해 **LLM(대규모 언어 모델)**과 상호작용하도록 설계되었으며, 특히 **실행 피드백 루프**를 통해 AI가 코드를 개선하고 학습하는 독창적인 기능을 제공합니다.
* **컴파일러/에뮬레이터 & IDE:** MetaVM 생태계 내에서 MiniLang 코드의 개발, 실행 및 분석을 지원하는 도구입니다.

**핵심 비전:**

이 플랫폼은 연구자, 학생, 그리고 잠재적으로 개발자들이 다음을 수행할 수 있도록 지원합니다:
1.  **자신만의 AI 중심 중간 표현(IR)을 설계하고 실험합니다.**
2.  **이러한 IR을 경량 LLM과 통합합니다.**
3.  **엣지 서버나 특수 하드웨어를 대상으로 하는 효율적인 실행 모델을 탐구합니다.**

본질적으로 MetaVM은 사용자 및 AI(넓게는 '클라이언트' 또는 '의도 소스'로 지칭)와 상호작용하는 프로그래밍 가능한 계층 역할을 합니다. 이는 최적화의 대상이 되는 동시에, 관련된 AI 모델에게 학습 피드백의 원천이 되는 실행 환경을 제공합니다. 상호작용은 단순한 요청/결과 처리를 넘어, 모니터링 로그 및 성능 지표에 의해 구동되는 지속적인 최적화 루프를 포함합니다.

*(향후 목표: 클라우드 네이티브 컴퓨팅 플랫폼으로 발전)*

---

## 🎓 활용 분야

* **컴퓨터 과학 교육:** DSL/VM/IR 설계, 파서/인터프리터 구현, 병렬 처리 개념에 대한 실습 경험.
* **AI/데이터 사이언스 교육:** 맞춤형 분석 언어를 사용한 실용적이고 인터랙티브한 학습.
* **중소기업 데이터 워크로드 처리:** 중소기업(SME)이 자연어를 통해 데이터 처리를 요청하고, 이를 효율적으로 (잠재적으로 CUDA 가속) 실행하여 신속한 분석 지원.
* **경량 모델 추론:** 미세조정된(Fine-tuned) LLM과 MiniLang DSL을 결합하여 저비용 추론 솔루션 실험.
* **연구 플랫폼:** 자연어-코드 변환, 프로그램 합성, AI 검증 등의 분야를 위한 연구 테스트베드.
* **(향후) 엣지 컴퓨팅:** `llvmlite`와의 잠재적 통합을 통해 RISC-V 기반 시스템과 같은 저전력 환경 지원.

---

## 🧰 기술 스택

* **핵심 개발:** Python 3.9+
* **파싱:** Lark (MiniLang용 파서 생성기)
* **데이터 처리:** Pandas, NumPy
* **AI / LLM:**
    * 범용 LLM (예: GPT-4, Claude 3, Gemini)과의 API 연동.
    * 특화 작업을 위한 미세조정 모델 (예: Phi-3, TinyLlama) 활용 목표.
    * PyTorch (로컬 LLM 추론/미세조정 가능성 대비).
* **개발 환경:**
    * JupyterLab (웹 IDE의 잠재적 기반)
    * VS Code (Remote Development 지원 포함)
* **실행 및 인프라:**
    * CUDA (GPU 가속용)
    * Docker, Conda (환경 관리용)
    * **(향후)** `llvmlite` (저수준 IR 실행 / 엣지 컴퓨팅용)

---

## 🏛️ 시스템 아키텍처 개요 (MetaVM 시스템 구성 요소)

MetaVM은 사용자 의도에 기반한 MiniLang 코드 생성 및 실행, 피드백 기반의 지속적 성능 개선을 목표로 하는 모듈형 AI 협업 시스템입니다. 이를 위해 다음과 같은 주요 구성 요소로 구성됩니다.

### 1. 사용자/AI 협업 서버 (**Collab Server**)
사용자의 작업 의도를 파악하고 MiniLang 코드로 변환하는 역할을 수행하는 프론트엔드 역할의 서버입니다.

* **주요 역할:**
  * 사용자(인간 개발자)의 CLI / 웹 UI 요청 수신
  * 범용 LLM (예: GPT-4 API) 및 미세조정된 경량 LLM과 협력하여 사용자의 자연어 요청을 MiniLang 코드로 변환
  * 작성된 MiniLang 코드 및 작업 명세를 엔진 서버로 전송
  * 엔진 서버의 실행 결과를 사용자에게 반환
  * 로그 서버로부터 수집된 실행 데이터를 바탕으로 LLM 또는 코드 템플릿 개선 작업 수행 (예: 프롬프트 개선, 코드 생성 전략 업데이트 등)

* **기능 구성:**
  * 사용자 인터페이스 (CLI / Web UI)
  * LLM 연동 모듈 (범용 API + Fine-tuned 로컬 LLM)
  * 로그 분석 기반 최적화 모듈

### 2. MetaVM 엔진 서버 (**Engine Server**)
MiniLang 코드를 실행하고 로그를 생성하는 백엔드 실행 서버입니다.

* **주요 역할:**
  * MiniLang 코드 실행 및 결과 생성
  * 내부 IR (SGR-ML → LIR-ML) 기반 파싱 및 실행
  * 실행 과정에서 발생하는 메트릭과 로그를 로깅 서버로 전달
  * 협업 서버와 stateless API 형태로 연동

* **서브 시스템 구성:**
  * **Executor:** MiniLang 구문 분석 및 실행기
  * **IR Translator:** MiniLang → SGR-ML → (선택적) LIR-ML 변환
  * **Metrics Collector:** 성능 지표 및 실행 로그 수집
  * **REPL CLI (개발 및 테스트용):** 직접 MiniLang 스크립트 실행 지원

### 3. 로그 서버 (**Logging Server**)
엔진 서버에서 수집한 실행 로그와 성능 지표를 저장, 관리, 분석하는 서버입니다.

* **주요 역할:**
  * 모든 실행 세션의 로그, 사용자 요청, 메트릭 저장
  * 협업 서버 또는 분석 시스템에 로그 API 제공
  * 장기적인 성능 개선 및 시스템 튜닝의 근거 데이터 제공

* **구성:**
  * 구조화된 로그 저장소 (예: JSON, Parquet 기반)
  * 검색/필터링 기능 (예: ElasticSearch 또는 SQL 기반)

---

## 🧭 시스템 상호작용 흐름

1. 사용자는 **협업 서버의 UI/CLI**를 통해 작업 요청을 보냅니다 (자연어 또는 MiniLang 코드).
2. 협업 서버는 의도를 분석하고 필요한 경우 LLM을 통해 MiniLang 코드로 변환합니다.
3. 생성된 MiniLang 코드는 **엔진 서버**로 전달되어 실행됩니다.
4. 엔진 서버는 작업을 실행하고, 실행 결과를 협업 서버에 반환합니다.
5. 동시에 로그 및 메트릭은 **로깅 서버**에 저장됩니다.
6. 협업 서버는 로그 분석을 통해 생성 코드 개선 또는 시스템 튜닝 작업을 수행합니다.

---

## 🔄 최적화 루프

* **최적화 대상:**

  * LLM 기반 MiniLang 코드 생성 품질
  * MiniLang → IR 변환 효율
  * 엔진 서버 실행 성능 (컴파일, 캐시, 병렬화 전략 등)

* **작동 방식:**

  * 협업 서버가 로깅 서버로부터 주기적으로 데이터를 수집하거나 실시간 스트리밍 처리
  * 생성된 로그 기반으로 LLM 프롬프트 개선 또는 로컬 LLM 재학습
  * IR 파이프라인 최적화 (예: 불필요한 연산 제거, 실행 캐시 활용 등)

---

## ✅ 1단계: MiniLang 기초 및 CLI 구축

* **목표:** 기본적인 MiniLang DSL 문법, 파서, 그리고 명령줄 인터프리터를 구축합니다.
* **작업:**
    * Lark를 사용하여 초기 MiniLang DSL 문법 정의.
    * 해당 파서 구축.
    * 기본 MiniLang 스크립트 실행을 위한 Python 기반 인터프리터 구현 (예: Transformer 패턴 활용).
    * REPL을 지원하는 CLI Subsystem 개발.
* **예시 사용 사례 및 코드:** 타이타닉 데이터셋 로딩 및 기본적인 Pandas 유사 통계 분석 수행.

    ```minilang
    # example.ml
    # CSV 파일에서 데이터 로드
    let data = load_csv("titanic.csv")

    # 기본 통계량(평균, 표준편차, 50% 백분위수) 계산 및 출력
    # stats 함수는 내부적으로 Python Interop을 통해 pandas를 사용할 수 있음
    print stats(data, ["mean", "std", "50%"])
    ```

    *예상 출력:* 계산된 통계량을 나타내는 표현 (예: Pandas DataFrame 요약과 유사).

* **추가 예제:** 엑셀 파일 병합, 피벗 테이블 생성, 기본 플롯팅 연동 등 일반적인 데이터 작업 예제 구현.

---

## ☑️ 로드맵 (향후 단계)

* **2단계: MetaVM IR 구현**
    * MiniLang 언어 명세 확장.
    * MiniLang -> SGR-ML (Semantic Graph Representation) 변환 파이프라인 구축.
    * MetaVM 엔진 내 SGR-ML 인터프리터 개발.
* **3단계: LLM 연동 강화**
    * 강력한 Prompt -> MiniLang/SGR-ML 자동 변환 기능 개발.
    * 코드 검증 및 개선을 위한 LLM (예: Phi-3 활용) 기반 실행 피드백 루프 구현 및 테스트.
* **4단계: 최적화된 실행 백엔드**
    * LIR-ML (Low-level IR) 명세 정의.
    * SGR-ML -> LIR-ML 컴파일 구현.
    * `llvmlite`를 활용한 최적화된 LIR-ML 실행을 위한 MetaVM 에뮬레이터 개발.
    * 특정 고성능 연산 가속을 위한 CUDA 백엔드 통합.
* **5단계: 엣지 및 산업 응용**
    * 엣지 배포를 위한 `llvmlite` -> RISC-V 코드 생성 경로 개발.
    * 일반적인 중소기업 사용 사례(예: 재고 분석, 판매 예측)를 위한 템플릿 라이브러리 구축.
    * RISC-V 기반 엣지 서버용 배포 패키지 생성.

---

## 🚀 개발 및 대상 환경

* **GPU:** NVIDIA A100 x4 (또는 유사한 CUDA 지원 GPU)
* **CPU:** 멀티코어 CPU (예: Intel Xeon 64-Core)
* **메모리:** 512GB RAM (또는 대상 워크로드에 충분한 메모리)
* **OS:** Ubuntu 22.04 LTS (또는 호환되는 Linux 배포판)
* **소프트웨어:** CUDA 12.x
* **(향후 대상):** RISC-V 기반 엣지 서버

---

## ✨ 비전: MetaVM 생태계를 위한 특화 LLM

장기 비전은 MetaVM과 깊이 통합된 특화 LLM(sLLM)을 개발하거나 미세조정하는 것을 포함하며, 이는 다음을 목표로 합니다:

* 핵심 작업에 대한 외부 범용 LLM 의존성 최소화.
* MiniLang/SGR-ML 구문 및 의미론에 특화된 코드 생성 및 개선 최적화.
* 다중 사용자 환경에서의 전반적인 시스템 효율성 및 성능 향상.
* 사용자 요청을 실행 가능한 결과로 변환하는 과정의 신뢰성 및 정확성 보장.
* 다양한 응용 도메인 및 사용자 요청 지원 확장.
* 다양한 실행 환경(GPU, CPU, RISC-V, 에뮬레이션) 대상 코드 생성.
* 동일 요청에 대해 동일 결과를 생성하는 결정론적 실행을 MetaVM 엔진이 지원하도록 보조.

---

## 🔗 기여 방법

* Pull Request는 언제나 환영합니다! 기여 가이드라인(TODO: 링크 추가)을 참고해주세요.
* 버그 보고나 기능 요청은 GitHub Issues 탭을 이용해주세요.
* 토론이나 질문은 GitHub Discussions 탭을 이용해주세요.
* **특히 중소기업 사용 사례나 엣지 컴퓨팅 시나리오와 관련된 새로운 활용 분야 제안을 환영합니다.**

---

## 📃 라이선스

MIT License